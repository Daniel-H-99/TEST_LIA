env:
    raw_path: '/mnt/hdd/minyeong_workspace/Experiment/data'
    checkpoint_path: '/mnt/hdd/minyeong_workspace/checkpoints'
    proc_path: '/mnt/hdd/minyeong_workspace//Experiment/proc'
    res_path: 'res'
const:
    SUCCESS: 1
    FAILED: 0
config:
    common:
        checkpoints:
            landmark_model:
                dir: '@checkpoint_path/landmark'
            model:
                model: '@checkpoint_path/lia/vox.pt'
                config: 
                    channel_multiplier: 1
                    size: 256
                    latent_dim_style: 512
                    latent_dim_motion: 20
                    dataset: 'vox'
                    ckpt: '@checkpoint_path/lia/vox.pt'                 
        attr:
            fps: 25
    preprocess:
        input:
            dir: '@raw_path' 
        output: 
            dir: '@proc_path'
    inference:
        attr:
            source_image: ''
            driving_video: ''
            result_video: ''
            driven_dir: ''
            from_flame: False
            gen: 'spade'
            ignore_emotion: True
            relative: True 
            adapt_scale: True 
            find_best_frame: False
            yaw: None
            pitch: None
            roll: None
            pca_path: "@checkpoint_path/BFv2v/eye_pca.pt"
        input: 
            dir: '@proc_path'
        output:
            dir: '@res_path'
dynamic:
    gpus: [0]
    mode: 'pair'
    input_as_file: True
    inputs:
        pair: 'inputs/vox_eval_group_3_hetero.txt'
    label: 'vox_eval_group_3_hetero'
    rewrite: False
    save_frames: True
    processed_inputs: True
    skip_eval: True
    relative_headpose: True
    load_exp: '/home/server19/minyeong_workspace/LIA/test/res/vox_eval_group_3_hetero_2022-10-31T09:02:24/materials.pt'

    
    



